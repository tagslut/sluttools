#!/usr/bin/env python3
import os
import re
import glob
import csv
import json
import random
import asyncio
import aiofiles
import unicodedata
import logging
import sys
from logging.handlers import RotatingFileHandler
from pathlib import Path
import sqlite3
import concurrent.futures
from concurrent.futures import ThreadPoolExecutor
from tqdm import tqdm
import subprocess

from rapidfuzz import fuzz, process
from rich.console import Console
from rich.text import Text
from rich.prompt import Prompt, Confirm
from rich.live import Live
from rich.align import Align
from mutagen._file import File as MutagenFile  # For audio metadata

import sqlite3
import time
from functools import lru_cache
from pathlib import Path
import pandas as pd

################################################################################
# CONFIGURATION
################################################################################

console = Console()
file_handler = RotatingFileHandler("script.log", maxBytes=1024*1024, backupCount=5)
logging.getLogger().addHandler(file_handler)

FLAC_LIBRARY_DIR = "/Volumes/sad/MUSIC2"
AUTO_MATCH_THRESHOLD = 80  # High confidence for auto-match
REVIEW_THRESHOLD = 60      # Lower threshold for manual review


# OUTPUT DIRECTORY – all generated files land here
OUTPUT_DIR = Path.home() / "Music" / "Mishmash"
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# SQLite index for FLAC library
DB_PATH = Path("/Volumes/sad/.flac_index.db")
CACHE_TTL = 3600  # seconds

# Path to qobuz-dl skip database
SKIP_DB_PATH = Path.home() / ".config/qobuz-dl/qobuz_dl.db"

@lru_cache(maxsize=100_000)
def normalize_string(s: str) -> str:
    s = unicodedata.normalize("NFD", s.lower())
    s = "".join(c for c in s if unicodedata.catcdgegory(c) != "Mn")
    return re.sub(r"[^\w\s]+", " ", s).strip()

def open_db():
    conn = sqlite3.connect(DB_PATH)
    conn.execute(
        """
        CREATE TABLE IF NOT EXISTS flacs (
            path TEXT PRIMARY KEY,
            norm TEXT NOT NULL,
            mtime INTEGER NOT NULL,
            artist TEXT,
            album TEXT,
            title TEXT,
            trackno TEXT,
            year TEXT,
            format_json TEXT
        )
        """
    )

    # Add missing columns if necessary
    expected_columns = ["artist", "album", "title", "trackno", "year", "format_json"]
    cur = conn.cursor()
    cur.execute("PRAGMA table_info(flacs)")
    existing_columns = [row[1] for row in cur.fetchall()]

    for column in expected_columns:
        if column not in existing_columns:
            cur.execute(f"ALTER TABLE flacs ADD COLUMN {column} TEXT")

    conn.execute("CREATE INDEX IF NOT EXISTS idx_norm ON flacs(norm)")
    conn.execute("CREATE INDEX IF NOT EXISTS idx_artist ON flacs(artist)")
    conn.execute("CREATE INDEX IF NOT EXISTS idx_album ON flacs(album)")
    return conn

def refresh_library(library_dir):
    conn = open_db()
    cur = conn.cursor()

    # Purge vanished files
    for (p,) in cur.execute("SELECT path FROM flacs"):
        if not os.path.exists(p):
            cur.execute("DELETE FROM flacs WHERE path=?", (p,))

    # Add/update changed files
    files = glob.glob(os.path.join(library_dir, "**", "*.flac"), recursive=True)
    console.print(f"[cyan]Scanning {len(files)} FLAC files in library…[/cyan]")

    def process_file(p):
        # Create a new connection for each thread
        thread_conn = sqlite3.connect(DB_PATH)
        thread_conn.execute("PRAGMA busy_timeout = 3000")  # Wait up to 3 seconds if locked
        thread_cur = thread_conn.cursor()

        m = int(os.path.getmtime(p))
        thread_cur.execute("SELECT mtime FROM flacs WHERE path=?", (p,))
        row = thread_cur.fetchone()
        norm = normalize_string(Path(p).stem)

        if row and row[0] == m:
            # Skip unchanged files
            thread_conn.close()
            return

        # Read tags via Mutagen
        tags = read_audio_metadata(p)
        # Read full ffprobe format JSON
        fmt = get_format_json(p)
        fmt_json = json.dumps(fmt) if fmt else None

        values = (
            p, norm, m,
            tags.get("artist"),
            tags.get("album"),
            tags.get("title"),
            tags.get("trackno"),
            tags.get("year"),
            fmt_json
        )

        # Retry logic for database locked
        for attempt in range(5):
            try:
                if not row:
                    thread_cur.execute(
                        """
                        INSERT INTO flacs (
                            path, norm, mtime, artist, album, title, trackno, year, format_json
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                        """,
                        values
                    )
                else:
                    thread_cur.execute(
                        """
                        REPLACE INTO flACS (
                            path, norm, mtime, artist, album, title, trackno, year, format_json
                        ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                        """,
                        values
                    )
                thread_conn.commit()
                break  # Success
            except sqlite3.OperationalError as e:
                if 'database is locked' in str(e):
                    time.sleep(0.2 * (attempt + 1))  # Exponential backoff
                else:
                    raise
        thread_conn.close()

    # Parallelize file processing
    with ThreadPoolExecutor(max_workers=8) as executor:
        list(tqdm(executor.map(process_file, files), total=len(files), desc="Scanning FLACs", unit="file"))

    conn.close()


################################################################################
# DESIGN RENDERER – EXACT LAYOUT
################################################################################

def render_design_box(offset: int) -> Text:
    """
    Build a 70-character wide box matching your design:

      - A top border of dashes in bold green.

      - Three interior lines, each 70 characters wide.
        Each interior line consists of:
          • A left heart and a right heart.
             Line 1: hearts in red,
             Line 2: hearts in yellow,
             Line 3: hearts in blue.
          • In between, the text "♫ GEORGIE'S PLAYLIST MAGIC BOX ♫" is centered.
             The interior text is animated per character by shifting colors in a R→Y→B cycle,
             based on the given offset.

      - A bottom border consisting solely of dashes (in bold green)
        with the Arabic text "هذا من فضل ربي" centered in bold dark green.
    """
    total_width = 70
    interior_width = total_width - 2  # account for the left/right heart

    text_content = "♫ GEORGIE'S PLAYLIST MAGIC BOX ♫"
    text_length = len(text_content)  # expected to be 31
    total_padding = interior_width - text_length  # e.g., 68 - 31 = 37
    pad_left = total_padding // 2
    pad_right = total_padding - pad_left

    # Function to animate interior text per character
    def animate_text(text: str, offset: int) -> Text:
        colors = ["red", "yellow", "blue"]
        animated = Text()
        for i, ch in enumerate(text):
            animated.append(ch, style=f"bold {colors[(i + offset) % 3]}")
        return animated

    box = Text()
    # Add top border: a full-width line of dashes in bold green.
    top_line = Text("─" * total_width, style="bold green")
    box.append(top_line)
    box.append("\n")

    # Build three interior lines with fixed hearts (colors fixed per line)
    heart_colors = ["red", "yellow", "blue"]
    for i in range(3):
        line = Text()
        line.append("♥", style=f"bold {heart_colors[i]}")
        line.append(" " * pad_left, style="bold green")
        # Animate the text content with the offset (each character already styled)
        line.append(animate_text(text_content, offset))
        line.append(" " * pad_right, style="bold green")
        line.append("♥", style=f"bold {heart_colors[i]}")
        box.append(line)
        box.append("\n")

    # Build bottom border: only dashes with Arabic text centered.
    arabic_text = "هذا من فضل ربي"
    arabic_length = len(arabic_text)  # expected 14
    available = total_width - arabic_length  # 70 - 14 = 56
    dashes_each = available // 2  # e.g., 28 on each side
    bottom_line = Text("─" * dashes_each, style="bold green")
    bottom_line.append(arabic_text, style="bold dark_green")
    bottom_line.append("─" * dashes_each, style="bold green")
    box.append(bottom_line)
    return box

################################################################################
# ANIMATED TITLE WITH BLINKING ENTER PROMPT
################################################################################

class PlaylistUI:
    def __init__(self):
        self.console = Console()

    async def animate_title(self, refresh_rate: float = 0.2, wait_time: float = 4.0):
        """
        Animate the design box for 'wait_time' seconds.
        After wait_time seconds, add a blinking "ENTER" prompt (in bold dark grey)
        centered below the box, blinking on/off at the same refresh rate until the user presses Enter.
        The interior text colors animate by shifting per-character colors based on the offset.
        """
        start_time = asyncio.get_event_loop().time()
        # Wait for user input in a background thread.
        enter_future = asyncio.get_event_loop().run_in_executor(None, input, "")
        with Live(console=self.console, refresh_per_second=int(1/refresh_rate)) as live:
            while True:
                elapsed = asyncio.get_event_loop().time() - start_time
                offset = int(elapsed * 2)  # adjust speed of color shift as needed
                box_text = render_design_box(offset)
                if elapsed >= wait_time:
                    # Blinking ENTER prompt: alternate between "ENTER" and spaces.
                    if int(elapsed / refresh_rate) % 2 == 0:
                        prompt_text = "ENTER"
                    else:
                        prompt_text = "     "
                    pad_left = (70 - len("ENTER")) // 2
                    pad_right = 70 - len("ENTER") - pad_left
                    enter_line = " " * pad_left + prompt_text + " " * pad_right

                    combined = Text()
                    combined.append(box_text)
                    combined.append("\n\n")
                    combined.append(enter_line, style="bold dark_grey")
                    live.update(Align.center(combined))
                else:
                    live.update(Align.center(box_text))
                if enter_future.done():
                    break
                await asyncio.sleep(refresh_rate)

################################################################################
# FUZZY MATCHING, SCANNING, & M3U GENERATION (UNCHANGED)
################################################################################


def combined_fuzzy_ratio(a, b):
    a_norm = normalize_string(a)
    b_norm = normalize_string(b)
    score1 = fuzz.ratio(a_norm, b_norm)
    score2 = fuzz.partial_ratio(a_norm, b_norm)
    score3 = fuzz.token_set_ratio(a_norm, b_norm)
    return max(score1, score2, score3)


def read_audio_metadata(path):
    meta = {}
    try:
        audio = MutagenFile(path, easy=True)
        if not audio:
            return meta
        if "artist" in audio:
            meta["artist"] = audio["artist"][0]
        if "album" in audio:
            meta["album"] = audio["album"][0]
        if "title" in audio:
            meta["title"] = audio["title"][0]
        if "tracknumber" in audio:
            tn = audio["tracknumber"][0].split("/")[0]
            meta["track"] = tn
        if "date" in audio:
            meta["year"] = audio["date"][0]
    except Exception as e:
        console.print(f"[red]Error reading metadata for {path}: {e}[/red]")
    return meta

PATTERN_FULL = re.compile(
    r"^(?P<artist>.*?) - \((?P<year>\d{4})\) (?P<album>.*?) - (?P<disc>\d{2})-(?P<track>\d{2})\.\s(?P<title>.*)\.(?P<ext>\w+)$"
)
PATTERN_SINGLE = re.compile(
    r"^(?P<track>\d{2})\.\s(?P<title>.*)\.(?P<ext>\w+)$"
)


async def parse_m3u_file(file_path):
    tracks = []
    encodings = ["utf-8", "iso-8859-1", "windows-1252"]
    for enc in encodings:
        try:
            async with aiofiles.open(file_path, "r", encoding=enc) as fh:
                lines = await fh.readlines()
                for line in lines:
                    line = line.strip()
                    if line and not line.startswith("#"):
                        # Use empty strings for missing metadata
                        tracks.append({"artist": "", "album": "", "track": line, "title": ""})
            nm = os.path.splitext(os.path.basename(file_path))[0]
            return nm, tracks
        except UnicodeDecodeError:
            continue
        except Exception as e2:
            console.print(f"[red]Error reading M3U: {e2}[/red]")
    return os.path.splitext(os.path.basename(file_path))[0], []

async def parse_json_file(file_path):
    try:
        async with aiofiles.open(file_path, "r", encoding="utf-8") as jf:
            cont = await jf.read()
            data = json.loads(cont)
            if isinstance(data, list):
                data = data[0]
            nm = data.get("name", os.path.splitext(os.path.basename(file_path))[0])
            raw = data.get("tracks", [])
            out = []
            for r in raw:
                out.append({
                    "artist": r.get("artist", ""),
                    "album": r.get("album", ""),
                    "track": r.get("track", ""),
                    "title": r.get("title", "")
                })
            return nm, out
    except Exception as ex:
        console.print(f"[red]Error reading JSON: {ex}[/red]")
    return os.path.splitext(os.path.basename(file_path))[0], []

async def parse_csv_file(file_path):
    out = []
    try:
        with open(file_path, "r", encoding="utf-8") as cf:
            rd = csv.DictReader(cf)
            for row in rd:
                out.append({
                    "track": row.get("track", row.get("title", "")),
                    "artist": row.get("artist", ""),
                    "album": row.get("album", ""),
                    "title": row.get("title", "")
                })
        nm = os.path.splitext(os.path.basename(file_path))[0]
        return nm, out
    except Exception as e2:
        console.print(f"[red]Error reading CSV: {e2}[/red]")
    return os.path.splitext(os.path.basename(file_path))[0], []

async def parse_xlsx_file(file_path):
    out = []
    try:
        df = pd.read_excel(file_path)
        nm = os.path.splitext(os.path.basename(file_path))[0]
        for _, row in df.iterrows():
            t = row.get("track", row.get("title", ""))
            a = row.get("artist", "")
            al = row.get("album", "")
            out.append({"track": t, "artist": a, "album": al, "title": row.get("title", "")})
        return nm, out
    except Exception as e2:
        console.print(f"[red]Error reading XLSX: {e2}[/red]")
    return os.path.splitext(os.path.basename(file_path))[0], []

async def parse_playlist_file(file_path):
    ext = file_path.lower().split(".")[-1]
    if ext == "m3u":
        return await parse_m3u_file(file_path)
    elif ext == "json":
        return await parse_json_file(file_path)
    elif ext == "csv":
        return await parse_csv_file(file_path)
    elif ext in ("xlsx", "xls"):
        return await parse_xlsx_file(file_path)
    else:
        console.print("[bold red]Unsupported playlist format.[/bold red]")
        return os.path.splitext(os.path.basename(file_path))[0], []

def build_search_string(entry):
    """
    Build the search string for matching: use artist and track/title fields.
    Falls back to just track/title if artist is missing.
    """
    parts = []

    # Get artist
    artist = entry.get("artist", "").strip()
    if artist:
        parts.append(artist)

    # Get track/title (prefer track, fall back to title)
    track = entry.get("track", "").strip()
    title = entry.get("title", "").strip()
    track_name = track or title

    if track_name:
        parts.append(track_name)

    return " ".join(parts).strip()


def match_entry(entry, flac_lookup):
    """Finds the best FLAC match for a playlist entry using pre-normalized lookup."""
    # Build search string using artist and track
    ss = build_search_string(entry)
    if not ss:
        return None, 0

    # Normalize the search string once
    ss_norm = normalize_string(ss)

    # Exact match shortcut using dictionary lookup
    flac_dict = {norm_basename: orig_path for orig_path, norm_basename in flac_lookup}
    if ss_norm in flac_dict:
        return flac_dict[ss_norm], 100  # Perfect match

    # Batch fuzzy matching using full search string
    matches = process.extract(ss_norm, flac_lookup, processor=lambda x: x[1], scorer=fuzz.ratio, limit=5)
    best_match = max(matches, key=lambda x: x[1], default=None)

    if best_match:
        # best_match[0] is the tuple (path, norm_basename)
        return best_match[0][0], best_match[1]

    # Fallback: try just the track name if artist + track didn't work
    track = entry.get("track", "").strip() or entry.get("title", "").strip()
    if track and track != ss:  # Only try if it's different from the full search
        track_norm = normalize_string(track)

        # Exact match with just track name
        if track_norm in flac_dict:
            return flac_dict[track_norm], 90  # High but not perfect

        # Fuzzy match with just track name
        track_matches = process.extract(track_norm, flac_lookup, processor=lambda x: x[1], scorer=fuzz.ratio, limit=5)
        track_best = max(track_matches, key=lambda x: x[1], default=None)

        if track_best:
            # track_best[0] is the tuple (path, norm_basename)
            return track_best[0][0], track_best[1] - 5  # Slightly lower confidence

    return None, 0

# Parallelized matching logic
def parallel_match_entries(entries, flac_lookup):
    """Matches multiple entries in parallel, returning (match, confidence) tuples."""
    with ThreadPoolExecutor(max_workers=8) as executor:
        results = list(executor.map(lambda entry: match_entry(entry, flac_lookup), entries))
    return results

async def create_m3u_file(out_path, matched_paths):
    if not out_path.lower().endswith(".m3u"):
        out_path += ".m3u"
    try:
        async with aiofiles.open(out_path, "w", encoding="utf-8") as f:
            await f.write("#EXTM3U\n")
            for p in matched_paths:
                await f.write(p + "\n")
        console.print(f"[bold green]Created M3U: {out_path}[/bold green]")
    except Exception as e2:
        console.print(f"[red]Error writing M3U: {e2}[/red]")

# -------------------------------------------------
# Build SongShift JSON directly from entries/matched
# -------------------------------------------------
def export_songshift_json_from_entries(entries, matched, output_json, playlist_name="Unmatched Tracks"):
    """Exports unmatched tracks to SongShift-ready JSON format."""
    tracks = []
    for i, m in enumerate(matched):
        if m is None:
            e = entries[i]
            title = e.get("title") or e.get("track") or build_search_string(e)
            artist = e.get("artist") or "Unknown Artist"
            tracks.append({"artist": artist.strip(), "track": title.strip()})

    payload = [{
        "service": "qobuz",
        "serviceId": None,
        "name": playlist_name,
        "tracks": tracks
    }]

    with open(output_json, "w", encoding="utf-8") as fh:
        json.dump(payload, fh, indent=2)
    console.print(f"[bold green]✓ JSON playlist saved → {output_json} ({len(tracks)} tracks)[/bold green]")

async def create_txt_file(out_path, unmatched_entries):
    """Creates a TXT file for unmatched entries."""
    try:
        async with aiofiles.open(out_path, "w", encoding="utf-8") as f:
            for entry in unmatched_entries:
                title = entry.get("title") or entry.get("track") or build_search_string(entry)
                artist = entry.get("artist") or "Unknown Artist"
                await f.write(f"{artist} - {title}\n")
        console.print(f"[bold green]✓ TXT file saved → {out_path} ({len(unmatched_entries)} lines)[/bold green]")
    except Exception as e:
        console.print(f"[red]Error writing TXT file: {e}[/red]")

def safe_confirm(prompt):
    """Helper function to confirm user input."""
    while True:
        response = input(f"{prompt} (y/n): ").strip().lower()
        if response in ['y', 'n']:
            return response == 'y'
        print("Please enter 'y' or 'n'.")

################################################################################
# MAIN FUNCTION
################################################################################

async def main():
    import argparse
    parser = argparse.ArgumentParser(description="FLAC playlist matcher")
    parser.add_argument('--refresh', action='store_true', help='Force refresh of FLAC library index')
    args = parser.parse_args()

    os.system('clear')
    console.clear()

    # 1) Run animated title with custom box and blinking ENTER prompt.
    ui = PlaylistUI()
    await ui.animate_title(refresh_rate=0.2, wait_time=4.0)

    os.system('clear')
    console.clear()

    # Prompt for input path
    console.print("[bold yellow]Enter a path (folder or playlist file):[/bold yellow] ", end="")
    path_in = input().strip().strip("'\"")
    console.print(f"[cyan]Input path: {path_in}[/cyan]")

    # Validate the path
    if not path_in:
        console.print("[red]No path provided. Please enter a valid path.[/red]")
        return

    if not os.path.exists(path_in):
        console.print(f"[red]Invalid path: {path_in}[/red]")
        return

    # Handle paths with spaces or special characters
    try:
        path_in = os.path.abspath(path_in)
    except Exception as e:
        console.print(f"[red]Error processing path: {e}[/red]")
        return

    # -------------------------------------------------------------------
    # Only refresh if --refresh is passed
    # -------------------------------------------------------------------
    if args.refresh:
        console.print("[cyan]Refreshing FLAC library index…[/cyan]")
        with console.status("[cyan]Refreshing FLAC library…[/cyan]", spinner="dots"):
            refresh_library(FLAC_LIBRARY_DIR)
        console.print("[bold green]FLAC library index refreshed[/bold green]")
    else:
        if not DB_PATH.exists():
            console.print(f"[red]FLAC index database not found: {DB_PATH}\nRun with --refresh to create it.[/red]")
            return
        else:
            console.print("[green]FLAC library index found; skipping refresh[/green]")

    entries = []
    source_name = os.path.basename(path_in)
    if os.path.isdir(path_in):
        console.print(f"[cyan]Scanning directory: {path_in}[/cyan]")
        # No directory scan; treat as playlist with basenames
        entries = []
        for f in glob.glob(os.path.join(path_in, "**", "*.*"), recursive=True):
            base = os.path.basename(f)
            entries.append({"title": base})
        source_name = os.path.basename(os.path.normpath(path_in))
    else:
        try:
            nm, tracks = await parse_playlist_file(path_in)
            console.print(f"[green]Loaded {len(tracks)} track(s) from {nm}[/green]")
            if not tracks:
                console.print("[yellow]No tracks found in the playlist file.[/yellow]")
                return
            entries = tracks
            source_name = nm
        except FileNotFoundError:
            console.print(f"[red]File not found: {path_in}[/red]")
            return
        except json.JSONDecodeError:
            console.print(f"[red]Error decoding JSON in file: {path_in}[/red]")
            return
        except Exception as e:
            console.print(f"[red]Unexpected error parsing playlist file: {e}[/red]")
            return

    console.print(f"[cyan]Loaded {len(entries)} playlist entries[/cyan]")

    # Load lookup from standalone FLAC DB
    try:
        conn = sqlite3.connect(DB_PATH)
        # Get both the normalized filename and the actual metadata
        flac_rows = conn.execute("SELECT path, norm, artist, title FROM flacs").fetchall()
        conn.close()

        # Create lookup that includes both filename and metadata
        flac_lookup = []
        for path, norm, artist, title in flac_rows:
            flac_lookup.append((path, norm))

            # Also add metadata-based normalized strings if available
            if artist and title:
                metadata_string = normalize_string(f"{artist} {title}")
                if metadata_string != norm:  # Avoid duplicates
                    flac_lookup.append((path, metadata_string))
            elif title:
                title_string = normalize_string(title)
                if title_string != norm:
                    flac_lookup.append((path, title_string))

        entries_with_ids = []
        matched = []

        # Load skip IDs from qobuz-dl DB
        skip_ids = set()
        if SKIP_DB_PATH.exists():
            try:
                skip_conn = sqlite3.connect(SKIP_DB_PATH)
                rs = skip_conn.execute("SELECT id FROM downloads").fetchall()
                skip_ids = {str(r[0]) for r in rs}
                skip_conn.close()
            except Exception as e:
                console.print(f"[red]Error loading skip database: {e}[/red]")

        def match_one(item):
            entry, sid = item
            # Skip if already downloaded
            if sid and str(sid) in skip_ids:
                return None

            # Normalize search string using only basic fields
            norm = normalize_string(build_search_string(entry))

            # Exact match
            for path, n in flac_rows:
                if n == norm:
                    return path

            # Fallback fuzzy
            best = max(flac_rows, key=lambda x: combined_fuzzy_ratio(norm, x[1]))
            score = combined_fuzzy_ratio(norm, best[1])

            if score >= AUTO_MATCH_THRESHOLD:
                return best[0]

            return None

        # Use parallel matching for the actual entries
        console.print(f"[cyan]Matching {len(entries)} tracks against FLAC library...[/cyan]")

        # Debug: show a few search strings
        console.print("[yellow]Sample search strings:[/yellow]")
        for i, entry in enumerate(entries[:5]):
            search_str = build_search_string(entry)
            norm_str = normalize_string(search_str)
            console.print(f"  {i+1}. '{search_str}' → '{norm_str}'")

        match_results = parallel_match_entries(entries, flac_lookup)

        # Categorize matches by confidence
        auto_matched = []
        needs_review = []
        unmatched = []

        for i, (path, confidence) in enumerate(match_results):
            if confidence >= AUTO_MATCH_THRESHOLD:
                auto_matched.append((i, path, confidence))
            elif confidence >= REVIEW_THRESHOLD:
                needs_review.append((i, path, confidence))
            else:
                unmatched.append(i)

        console.print(f"[bold green]{len(auto_matched)} auto-matched[/bold green], "
                      f"[bold yellow]{len(needs_review)} need review[/bold yellow], "
                      f"[bold red]{len(unmatched)} unmatched[/bold red]")

        # Create final matches array
        matched: list[str | None] = [None] * len(entries)
        for i, path, confidence in auto_matched:
            matched[i] = path

        # Only prompt for review if there are uncertain matches AND user wants to review them
        # Since you said scores above 80 don't need review, we'll auto-accept uncertain ones by default
        review_all = False
        if needs_review:
            console.print(f"\n[yellow]Found {len(needs_review)} uncertain matches (scores 60-80).[/yellow]")
            console.print(f"[cyan]What would you like to do with uncertain matches?[/cyan]")
            console.print(f"  1. Review all matches ({len(auto_matched + needs_review)} tracks)")
            console.print(f"  2. Review only uncertain matches ({len(needs_review)} tracks)")
            console.print(f"  3. Auto-accept uncertain matches (recommended)")

            while True:
                choice = input("Select option [1-3]: ").strip()
                if choice == "1":
                    review_all = True
                    break
                elif choice == "2":
                    review_all = False
                    break
                elif choice == "3" or choice == "":  # Default to auto-accept
                    # Auto-accept all uncertain matches
                    for i, path, confidence in needs_review:
                        matched[i] = path
                    console.print(f"[green]Auto-accepted {len(needs_review)} uncertain matches.[/green]")
                    needs_review = []  # Clear the list so no review happens
                    break
                else:
                    console.print("[red]Invalid choice. Please enter 1, 2, or 3 (or just press Enter for option 3).[/red]")
        else:
            # No uncertain matches - all good matches were auto-accepted
            if auto_matched:
                console.print(f"[green]All {len(auto_matched)} matches above threshold {AUTO_MATCH_THRESHOLD} were auto-accepted.[/green]")

        # Manual review process - only run if we have uncertain matches and user wants to review
        if needs_review and (review_all or not review_all):
            tracks_to_review = []

            if review_all:
                # Review all matches (auto + uncertain)
                tracks_to_review = auto_matched + needs_review
                console.print(f"\n[yellow]Reviewing all {len(tracks_to_review)} matches...[/yellow]")
            else:
                # Review only uncertain matches
                tracks_to_review = needs_review
                console.print(f"\n[yellow]Reviewing {len(tracks_to_review)} uncertain matches...[/yellow]")

            for i, suggested_path, confidence in tracks_to_review:
                entry = entries[i]
                search_str = build_search_string(entry)

                # Get top 10 potential matches for this entry
                ss_norm = normalize_string(search_str)
                potential_matches = process.extract(
                    ss_norm,
                    [norm_basename for _, norm_basename in flac_lookup],
                    scorer=fuzz.ratio,
                    limit=10
                )

                # Convert to (path, score) tuples
                potential_with_paths = []
                for match, score, _ in potential_matches:  # Unpack 3 values: match, score, index
                    for path, norm in flac_lookup:
                        if norm == match:
                            potential_with_paths.append((path, score))
                            break

                # Show current match status
                if confidence >= AUTO_MATCH_THRESHOLD:
                    status = f"[green]AUTO-MATCHED (confidence: {confidence})[/green]"
                else:
                    status = f"[yellow]UNCERTAIN (confidence: {confidence})[/yellow]"

                console.print(f"\n{status}")
                console.print(f"[bold]Current match:[/bold] {Path(suggested_path).stem}")

                result = manual_review_match(entry, potential_with_paths, search_str, current_match=suggested_path)
                matched[i] = result

        # Count final results
        matched_count = sum(1 for m in matched if m)
        unmatched_count = len(entries) - matched_count

        console.print(f"[bold green]{matched_count} matched[/bold green], "
                      f"[bold red]{unmatched_count} unmatched[/bold red]")

        # List unmatched tracks for clarity
        if unmatched_count > 0:
            console.print("[bold underline]Unmatched tracks:[/bold underline]")
            for i, entry in enumerate(entries):
                if matched[i] is None:
                    name = entry.get("title") or entry.get("track") or build_search_string(entry)
                    console.print(f" • {name}")

        # Export unmatched tracks as SongShift JSON if requested
        if any(m is None for m in matched):
            if safe_confirm("[bold yellow]Export unmatched tracks as a SongShift-ready JSON playlist?[/bold yellow]"):
                json_name = OUTPUT_DIR / f"{source_name}_songshift.json"
                export_songshift_json_from_entries(entries, matched, json_name, playlist_name=source_name)

        # Ask about creating output files
        final_matches = [m for m in matched if m]
        if final_matches:
            if safe_confirm("[bold yellow]Create M3U playlist for matched tracks?[/bold yellow]"):
                out_m3u = OUTPUT_DIR / f"{source_name}_matched.m3u"
                await create_m3u_file(str(out_m3u), final_matches)

            if unmatched_count > 0 and safe_confirm("[bold yellow]Create TXT file for unmatched tracks?[/bold yellow]"):
                await create_txt_file(str(OUTPUT_DIR / f"{source_name}_unmatched.txt"), [e for i, e in enumerate(entries) if matched[i] is None])
        else:
            console.print("[bold yellow]No matches found. No files to create.[/bold yellow]")

        console.print("\n[bold green]Processing complete![/bold green]")

    except sqlite3.Error as e:
        console.print(f"[red]Database error: {e}[/red]")
        return

def get_format_json(path):
    """Extract format information using ffprobe."""
    try:
        result = subprocess.run(
            ["ffprobe", "-v", "quiet", "-print_format", "json", "-show_format", path],
            capture_output=True,
            text=True,
        )
        if result.returncode != 0:
            console.print(f"[yellow]Warning: ffprobe failed for {path}. Skipping file.[/yellow]")
            return {}
        return json.loads(result.stdout).get("format", {})
    except json.JSONDecodeError as e:
        console.print(f"[yellow]Warning: Invalid JSON from ffprobe for {path}. Skipping file.[/yellow]")
        return {}
    except Exception as e:
        console.print(f"[red]Error running ffprobe for {path}: {e}[/red]")
        return {}

async def parse_json_playlist(file_path):
    """Parses a JSON playlist file and extracts track details."""
    try:
        async with aiofiles.open(file_path, "r", encoding="utf-8") as jf:
            content = await jf.read()
            data = json.loads(content)
            if isinstance(data, list):
                data = data[0]  # Assume the first object contains the playlist
            tracks = data.get("tracks", [])
            return tracks
    except Exception as ex:
        console.print(f"[red]Error reading JSON playlist: {ex}[/red]")
        return []

async def match_json_playlist(json_path):
    """Matches tracks from a JSON playlist file with the FLAC database."""
    console.print(f"[cyan]Processing JSON playlist: {json_path}[/cyan]")

    # Parse the JSON playlist
    tracks = await parse_json_playlist(json_path)
    if not tracks:
        console.print("[red]No tracks found in the JSON playlist.[/red]")
        return

    # Load FLAC database
    conn = sqlite3.connect(DB_PATH)
    flac_rows = conn.execute("SELECT path, norm FROM flacs").fetchall()
    conn.close()

    matched = []
    unmatched = []

    for track in tracks:
        # Build search string and normalize
        search_string = build_search_string(track)
        norm_search_string = normalize_string(search_string)

        # Exact match
        exact_match = next((path for path, norm in flac_rows if norm == norm_search_string), None)
        if exact_match:
            matched.append(exact_match)
            console.print(f"[green]Exact match found: {exact_match}[/green]")
            continue

        # Fuzzy match
        best_match = max(flac_rows, key=lambda x: combined_fuzzy_ratio(norm_search_string, x[1]))
        score = combined_fuzzy_ratio(norm_search_string, best_match[1])

        if score >= AUTO_MATCH_THRESHOLD:
            matched.append(best_match[0])
            console.print(f"[blue]Fuzzy match found: {best_match[0]} (Score: {score})[/blue]")
        else:
            unmatched.append(track)
            console.print(f"[red]No match found for track: {search_string}[/red]")

    # Report results
    console.print(f"[bold green]{len(matched)} matched[/bold green], [bold red]{len(unmatched)} unmatched[/bold red]")

    # Export unmatched tracks only if requested
    if unmatched:
        if safe_confirm("[bold yellow]Export unmatched tracks as a SongShift-ready JSON playlist?[/bold yellow]"):
            json_name = OUTPUT_DIR / f"{Path(json_path).stem}_unmatched.json"
            export_songshift_json_from_entries(unmatched, [None] * len(unmatched), json_name, playlist_name="Unmatched Tracks")

        if safe_confirm("[bold yellow]Create TXT file for unmatched tracks?[/bold yellow]"):
            txt_name = OUTPUT_DIR / f"{Path(json_path).stem}_unmatched.txt"
            await create_txt_file(str(txt_name), unmatched)

    # Create M3U for matched tracks only if requested
    if matched:
        if safe_confirm("[bold yellow]Create M3U playlist for matched tracks?[/bold yellow]"):
            m3u_name = OUTPUT_DIR / f"{Path(json_path).stem}_matched.m3u"
            await create_m3u_file(str(m3u_name), matched)
    else:
        console.print("[bold yellow]No matches found. No files to create.[/bold yellow]")

def manual_review_match(entry, potential_matches, search_string, current_match=None):
    """Let user manually select from potential matches or skip."""
    console.print(f"\n[yellow]Review match for:[/yellow] [bold]{search_string}[/bold]")

    if current_match:
        current_filename = Path(current_match).stem
        console.print(f"[green]Current match:[/green] [bold]{current_filename}[/bold]")
        console.print(f"[green]Full path:[/green] {current_match}")

    console.print("\n[yellow]Options:[/yellow]")
    console.print("  a. [green]Accept current match[/green]" if current_match else "  0. [red]Skip this track[/red]")
    console.print("  0. [red]Skip this track[/red]")

    console.print("[yellow]Alternative matches:[/yellow]")
    for i, (path, score) in enumerate(potential_matches[:10], 1):
        filename = Path(path).stem
        # Highlight if this is the current match
        if current_match and path == current_match:
            console.print(f"  {i}. [bold green]{filename}[/bold green] (Score: {score}) [green]← CURRENT[/green]")
        else:
            console.print(f"  {i}. [cyan]{filename}[/cyan] (Score: {score})")

    console.print("  m. [blue]Manual file browser[/blue]")

    while True:
        if current_match:
            choice = input("\nSelect option [a, 0-10, m]: ").strip().lower()
        else:
            choice = input("\nSelect option [0-10, m]: ").strip().lower()

        if choice == "a" and current_match:
            return current_match
        elif choice == "0":
            return None
        elif choice == "m":
            console.print("[blue]Enter the full path to the FLAC file (or press Enter to skip):[/blue]")
            manual_path = input().strip().strip("'\"")
            if manual_path and os.path.exists(manual_path) and manual_path.lower().endswith('.flac'):
                return manual_path
            elif manual_path:
                console.print("[red]Invalid path or not a FLAC file.[/red]")
                continue
            else:
                return None
        else:
            try:
                idx = int(choice)
                if 1 <= idx <= min(10, len(potential_matches)):
                    return potential_matches[idx - 1][0]
                else:
                    console.print("[red]Invalid choice. Please try again.[/red]")
            except ValueError:
                if current_match:
                    console.print("[red]Invalid input. Please enter 'a', a number, '0', or 'm'.[/red]")
                else:
                    console.print("[red]Invalid input. Please enter a number, '0', or 'm'.[/red]")

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        console.print("[bold red]Process interrupted by user (Ctrl+C). Exiting...[/bold red]")
        sys.exit(0)
